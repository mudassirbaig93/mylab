{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic modules\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt        \n",
    "%matplotlib inline\n",
    "\n",
    "#import feature selection modules\n",
    "from sklearn.feature_selection import mutual_info_classif,RFE,RFECV\n",
    "\n",
    "#import classification modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#import classification evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data load function\n",
    "def load_data():\n",
    "    dmfraud = pd.read_csv(\"medicalfraud.csv\")\n",
    "    return dmfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning function\n",
    "def cleaningup(dmfraud):\n",
    "    #write all the cleaning code here\n",
    "    print(\"dmfraud is all cleaned up..\")\n",
    "    return dmfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic analysis\n",
    "def basicanalysis(dmfraud):\n",
    "    print(\"Shape is:\\n\", dmfraud.shape)\n",
    "    print(\"Columns are:\\n\", dmfraud.columns)\n",
    "    print(\"Types are:\\n\", dmfraud.dtypes)\n",
    "    print(\"Statistical Analysis of Numerical Columns:\\n\", dmfraud.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string column analysis analysis\n",
    "def stringcolanalysis(dmfraud):\n",
    "    stringcols = dmfraud.select_dtypes(exclude=np.number)\n",
    "    fig = plt.figure(figsize = (8,10))\n",
    "    for i,col in enumerate(stringcols):\n",
    "        fig.add_subplot(4,2,i+1)\n",
    "        fig.savefig('Categorical.png')\n",
    "        dmfraud[col].value_counts().plot(kind = 'barh', color='black' ,fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical analysis\n",
    "#histograms and boxplots for all numerical columns\n",
    "#scatter plots (seaborn heatmaps)\n",
    "def numcolanalysis(dmfraud):\n",
    "    numcols = dmfraud.select_dtypes(include=np.number)\n",
    "    for col in numcols:\n",
    "        fig = plt.figure(figsize = (5,5))\n",
    "        sb.boxplot(dmfraud[col], color='grey', linewidth=1)\n",
    "        plt.tight_layout()\n",
    "        plt.title(col)\n",
    "        plt.savefig(\"Numerical.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_paid_to_date</th>\n",
       "      <th>number_presc_to_date</th>\n",
       "      <th>max_presc_to_date</th>\n",
       "      <th>max_presc_per_doctor</th>\n",
       "      <th>max_presc_per_hospital</th>\n",
       "      <th>max_presc_per_year</th>\n",
       "      <th>id</th>\n",
       "      <th>FRAUD_LABEL</th>\n",
       "      <th>amount_paid_per_year</th>\n",
       "      <th>amount_paid_per_hospital</th>\n",
       "      <th>amount_paid_per_doctor</th>\n",
       "      <th>amount_paid_to_prescription</th>\n",
       "      <th>amount_paid_total</th>\n",
       "      <th>number_presc_per_year</th>\n",
       "      <th>number_presc_per_hospital</th>\n",
       "      <th>number_presc_per_doctor</th>\n",
       "      <th>number_presc_to_prescription</th>\n",
       "      <th>number_presc_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>109.111328</td>\n",
       "      <td>71.316356</td>\n",
       "      <td>24.658738</td>\n",
       "      <td>40.935309</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>120</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.588010</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>0.942975</td>\n",
       "      <td>48.316478</td>\n",
       "      <td>27.854219</td>\n",
       "      <td>24.471927</td>\n",
       "      <td>402.352042</td>\n",
       "      <td>285</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.402561</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "      <td>159.592229</td>\n",
       "      <td>53.969161</td>\n",
       "      <td>26.888177</td>\n",
       "      <td>37.658748</td>\n",
       "      <td>401.610244</td>\n",
       "      <td>156</td>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>59.203803</td>\n",
       "      <td>43.843904</td>\n",
       "      <td>48.933583</td>\n",
       "      <td>19.248757</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>253</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>95.780922</td>\n",
       "      <td>38.195557</td>\n",
       "      <td>43.876891</td>\n",
       "      <td>40.236061</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>206</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_paid_to_date  number_presc_to_date  max_presc_to_date  \\\n",
       "0           100.000000                     0                  1   \n",
       "1           100.588010                     9                  1   \n",
       "2           100.402561                     0                  1   \n",
       "3           100.000000                     3                  1   \n",
       "4           100.000000                    22                  1   \n",
       "\n",
       "   max_presc_per_doctor  max_presc_per_hospital  max_presc_per_year  id  \\\n",
       "0                     1                       0                   0  21   \n",
       "1                     1                       9                   9  34   \n",
       "2                     1                       0                   0  35   \n",
       "3                     1                      84                   9  38   \n",
       "4                     1                      22                  22  24   \n",
       "\n",
       "   FRAUD_LABEL  amount_paid_per_year  amount_paid_per_hospital  \\\n",
       "0        False            109.111328                 71.316356   \n",
       "1        False              0.942975                 48.316478   \n",
       "2        False            159.592229                 53.969161   \n",
       "3        False             59.203803                 43.843904   \n",
       "4        False             95.780922                 38.195557   \n",
       "\n",
       "   amount_paid_per_doctor  amount_paid_to_prescription  amount_paid_total  \\\n",
       "0               24.658738                    40.935309         400.000000   \n",
       "1               27.854219                    24.471927         402.352042   \n",
       "2               26.888177                    37.658748         401.610244   \n",
       "3               48.933583                    19.248757         400.000000   \n",
       "4               43.876891                    40.236061         400.000000   \n",
       "\n",
       "   number_presc_per_year  number_presc_per_hospital  number_presc_per_doctor  \\\n",
       "0                    120                         37                       30   \n",
       "1                    285                         55                       35   \n",
       "2                    156                         64                       21   \n",
       "3                    253                         27                       35   \n",
       "4                    206                         47                       49   \n",
       "\n",
       "   number_presc_to_prescription  number_presc_total  \n",
       "0                            35                 400  \n",
       "1                            46                 402  \n",
       "2                            32                 402  \n",
       "3                            46                 400  \n",
       "4                            46                 400  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmfraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting manually\n",
    "def traintestsplit(dmfraud,split,random, label_col=''):\n",
    "    #make a copy of the label column and store in y\n",
    "    y = dmfraud[label_col].copy()\n",
    "    \n",
    "    #now delete the original\n",
    "    X = dmfraud.drop(label_col,axis=1)\n",
    "    \n",
    "    #manual split\n",
    "    trainX, testX, trainY, testY= train_test_split(X, y, test_size=split, random_state=random)\n",
    "    \n",
    "    return X, trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting through cross validation (you can try out different splitting methods)\n",
    "#KFold, RepeatedKFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "def cross_valid(X,y,split,repeat,random):\n",
    "    kf = RepeatedKFold(n_splits=split, n_repeats=repeat, random_state=random) \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        trainX, testX = X.iloc[train_index], X.iloc[test_index] \n",
    "        trainY, testY = y.iloc[train_index], y.iloc[test_index]\n",
    "    return trainX,trainY,testX,testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationmetrics(model,testX,testY):\n",
    "    predictions = model.predict(testX)\n",
    "    print(\"Prediction Vector: \\n\", predictions)\n",
    "    \n",
    "    #Accuracy\n",
    "    print(\"Accuracy: \\n\", accuracy_score(testY, predictions)*100)\n",
    "    \n",
    "    #Precision\n",
    "    print(\"Precision of Fraud Happening: \\n\", precision_score(testY, predictions,pos_label=1,labels=[0,1])*100)\n",
    "    \n",
    "    #Recall\n",
    "    print(\"Recall of Fraud Happening: \\n\", recall_score(testY, predictions,pos_label=1,labels=[0,1])*100)\n",
    "    \n",
    "    #get FPR (specificity) and TPR (sensitivity)\n",
    "    fpr , tpr, _ = roc_curve(testY, predictions)\n",
    "    \n",
    "    #AUC\n",
    "    print(\"AUC of Fraud Happening: \\n\",auc(fpr, tpr))\n",
    "    \n",
    "    #F-Score\n",
    "    print(\"F-Score OF Fraud Happening:\\n\", f1_score(testY, predictions))\n",
    "    \n",
    "    #confusion Matrix\n",
    "    \n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(testY, predictions,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Feature Selection (RFFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the important features given by RFFS\n",
    "def RFfeatureimportance(dmfraud, trainX, testX, trainY, testY, trees, random):\n",
    "    clf  = RandomForestClassifier(n_estimators=trees, random_state=random)\n",
    "    clf.fit(trainX,trainY)\n",
    "    validationmetrics(clf,testX,testY)\n",
    "    print(pd.Series(clf.feature_importances_, index=dmfraud.columns.values).sort_values(ascending=False)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features with importance >=threshold\n",
    "def MachineLearningwithRFFS():\n",
    "    #include all selected features in impftrs and last should be the label\n",
    "    impftrs = []\n",
    "    dmfraud = load_data()\n",
    "    dmfraud = cleaningup(dmfraud)\n",
    "    dmfraud = stringcolencoding(dmfraud)\n",
    "    dmfraud = dmfraud[impftrs]\n",
    "    dmfraud, trainX, testX, trainY, testY = traintestsplit(dmfraud,0.2,91)     \n",
    "    \n",
    "    print(\"\\n\\n Results for Logistic Regression.....\")\n",
    "    LogReg(dmfraud, trainX, testX, trainY, testY)\n",
    "    \n",
    "    print(\"\\n\\n Results for KNN.....\")\n",
    "    KNN(dmfraud, trainX, testX, trainY, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information Feature Selection (MIFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the important features given by MIFS\n",
    "def mutualinformation(dmfraud):\n",
    "    #make a copy of the label column and store in y\n",
    "    y = dmfraud[''].copy()\n",
    "    X = dmfraud.drop('',axis=1)\n",
    "    \n",
    "    mutual_info = mutual_info_classif(X,y,random_state=35)\n",
    "    results = pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)*100\n",
    "    results.to_csv(\"sortedfeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features with importance >=threshold\n",
    "def MachineLearningwithMIFS():\n",
    "    #include all selected features in impftrs and last should be the label\n",
    "    impftrs = []\n",
    "    dmfraud = load_data()\n",
    "    dmfraud = cleaningup(dmfraud)\n",
    "    dmfraud = stringcolencoding(dmfraud)\n",
    "    dmfraud = dmfraud[impftrs]\n",
    "    dmfraud, trainX, testX, trainY, testY = traintestsplit(dmfraud,0.2,91)     \n",
    "   \n",
    "    print(\"\\n\\n Results for Logistic Regression.....\")\n",
    "    LogReg(dmfraud, trainX, testX, trainY, testY)\n",
    "   \n",
    "    print(\"\\n\\n Results for KNN.....\")\n",
    "    KNN(dmfraud, trainX, testX, trainY, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Elimination Feature Selection (REFS) with Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XYsplit(dmfraud):\n",
    "    y = dmfraud['Pak_Win_yes'].copy()\n",
    "    X = dmfraud.drop('Pak_Win_yes',axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegRECV(X, y, random, split,repeat):\n",
    "    clf = LogisticRegression(solver='liblinear',penalty='l2')\n",
    "    selector = RFECV(estimator=clf, step=1, cv=split)\n",
    "    selector = selector.fit(X,y)\n",
    "    X = X[X.columns[selector.support_].tolist()]\n",
    "    trainX, trainY, testX, testY= cross_valid(X, y,split,repeat,random)\n",
    "    clf  = LogisticRegression(solver='liblinear',penalty='l2')\n",
    "    clf.fit(trainX , trainY)\n",
    "    validationmetrics(clf,testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNRECV(X, y, trees, random, split,repeat):\n",
    "    clf = RandomForestClassifier(n_estimators=trees, random_state=random)\n",
    "    selector = RFECV(estimator=clf, step=1, cv=split)\n",
    "    selector = selector.fit(X,y)\n",
    "    X = X[X.columns[selector.support_].tolist()]\n",
    "    \n",
    "    trainX, trainY, testX, testY= cross_valid(X, y,split,repeat,random)\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    validationmetrics(clf,testX,testY)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Elimination Feature Selection with out Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XYsplit(dmfraud):\n",
    "    y = dmfraud[''].copy()\n",
    "    X = dmfraud.drop('',axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegRE(X, y, random, split):\n",
    "    clf = LogisticRegression(solver='liblinear',penalty='l2')\n",
    "    selector = RFE(estimator=clf, step=1)\n",
    "    selector = selector.fit(X,y)\n",
    "    X = X[X.columns[selector.support_].tolist()]\n",
    "   \n",
    "    trainX, testX, trainY, testY= train_test_split(X, y, test_size=split, random_state=random)\n",
    "    clf  = LogisticRegression(solver='liblinear',penalty='l2')\n",
    "    clf.fit(trainX , trainY)\n",
    "    validationmetrics(clf,testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNRE(X, y, trees, random, split):\n",
    "    clf = RandomForestClassifier(n_estimators=trees, random_state=random)\n",
    "    selector = RFE(estimator=clf, step=1)\n",
    "    selector = selector.fit(X,y)\n",
    "    X = X[X.columns[selector.support_].tolist()]\n",
    "    \n",
    "    #trainX, trainY, testX, testY= cross_valid(X, y,split,repeat,random)\n",
    "    trainX, testX, trainY, testY= train_test_split(X, y, test_size=split, random_state=random)\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    validationmetrics(clf,testX,testY)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for RFE without Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmfraud = load_data()\n",
    "dmfraud = cleaningup(dmfraud)\n",
    "dmfraud = stringcolencoding(dmfraud)\n",
    "X, y = XYsplit(dmfraud)\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "LogRegRE(X,y,65,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmfraud = load_data()\n",
    "dmfraud = cleaningup(dmfraud)\n",
    "dmfraud = stringcolencoding(dmfraud)\n",
    "X, y = XYsplit(dmfraud)\n",
    "print(\"KNNRE\")\n",
    "KNNRE(X,y,100,59,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for RFE with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmfraud = load_data()\n",
    "dmfraud = cleaningup(dmfraud)\n",
    "dmfraud = stringcolencoding(dmfraud)\n",
    "X, y = XYsplit(dmfraud)\n",
    "print(\"LOGISTIC REGRESSION\")\n",
    "LogRegRECV(X,y,65,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNNRE\")\n",
    "KNNRECV(X,y,200,70,10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(dmfraud, trainX, testX, trainY, testY):\n",
    "    clf  = LogisticRegression()\n",
    "    clf.fit(trainX , trainY)\n",
    "    validationmetrics(clf,testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(dmfraud, trainX, testX, trainY, testY):\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(trainX , trainY)\n",
    "    validationmetrics(clf,testX,testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Center - II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Control Center (Initiate)\n",
    "dmfraud = load_data()\n",
    "dmfraud = cleaningup(dmfraud)\n",
    "#basicanalysis(dmfraud)\n",
    "#stringcolanalysis(dmfraud)\n",
    "#numcolanalysis(dmfraud)\n",
    "dmfraud = stringcolencoding(dmfraud)\n",
    "dmfraud, trainX, testX, trainY, testY = traintestsplit(dmfraud,0.2,91)\n",
    "#applying different feature selection methods\n",
    "#RFfeatureimportance(dmfraud, trainX, testX, trainY, testY, 1000, 65)\n",
    "print(\"\\n\\n\\n#########ML WITH RF WITHOUT CROSS VALIDATION#######\\n\\n\\n\")\n",
    "MLwithRFFtrImp()\n",
    "print(\"\\n\\n\\n#########ML WITH RF WITH CROSS VALIDATION#######\\n\\n\\n\")\n",
    "MLwithRFFtrImpCV(10,10,65)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
